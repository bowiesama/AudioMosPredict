{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netMosAvg</th>\n",
       "      <th>d2cLossAvg</th>\n",
       "      <th>e2eJitterAvg</th>\n",
       "      <th>d2cJitterAvg</th>\n",
       "      <th>e2eLossAvg</th>\n",
       "      <th>jitDepthAvg</th>\n",
       "      <th>playSpeedAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.97741</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.31220</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>286</td>\n",
       "      <td>17</td>\n",
       "      <td>1186</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.18346</td>\n",
       "      <td>31</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>31</td>\n",
       "      <td>2038</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06915</td>\n",
       "      <td>48</td>\n",
       "      <td>723</td>\n",
       "      <td>723</td>\n",
       "      <td>48</td>\n",
       "      <td>3032</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>61</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>61</td>\n",
       "      <td>4046</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   netMosAvg  d2cLossAvg  e2eJitterAvg  d2cJitterAvg  e2eLossAvg  jitDepthAvg  \\\n",
       "0    3.97741           4           125           125           4          534   \n",
       "1    3.31220          17           286           286          17         1186   \n",
       "2    2.18346          31           492           492          31         2038   \n",
       "3    1.06915          48           723           723          48         3032   \n",
       "4    1.00000          61           958           958          61         4046   \n",
       "\n",
       "   playSpeedAvg  \n",
       "0           1.2  \n",
       "1           1.0  \n",
       "2           1.0  \n",
       "3           1.0  \n",
       "4           1.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time, datetime\n",
    "df_data = pd.read_csv('/Users/wme/git/bowchen/AudioMosPredict/Audio_Mos_Predict/AllInOne.csv')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netMosAvg</th>\n",
       "      <th>d2cLossAvg</th>\n",
       "      <th>e2eJitterAvg</th>\n",
       "      <th>d2cJitterAvg</th>\n",
       "      <th>e2eLossAvg</th>\n",
       "      <th>jitDepthAvg</th>\n",
       "      <th>playSpeedAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.97741</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.31220</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>286</td>\n",
       "      <td>17</td>\n",
       "      <td>1186</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.18346</td>\n",
       "      <td>31</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>31</td>\n",
       "      <td>2038</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06915</td>\n",
       "      <td>48</td>\n",
       "      <td>723</td>\n",
       "      <td>723</td>\n",
       "      <td>48</td>\n",
       "      <td>3032</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>61</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>61</td>\n",
       "      <td>4046</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>78</td>\n",
       "      <td>1025</td>\n",
       "      <td>1025</td>\n",
       "      <td>78</td>\n",
       "      <td>4112</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>88</td>\n",
       "      <td>965</td>\n",
       "      <td>965</td>\n",
       "      <td>88</td>\n",
       "      <td>4184</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.62769</td>\n",
       "      <td>12</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>12</td>\n",
       "      <td>4084</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.87999</td>\n",
       "      <td>23</td>\n",
       "      <td>366</td>\n",
       "      <td>366</td>\n",
       "      <td>23</td>\n",
       "      <td>3224</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.74661</td>\n",
       "      <td>35</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>35</td>\n",
       "      <td>2706</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.02937</td>\n",
       "      <td>52</td>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>52</td>\n",
       "      <td>3373</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>65</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>65</td>\n",
       "      <td>3849</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>82</td>\n",
       "      <td>972</td>\n",
       "      <td>972</td>\n",
       "      <td>82</td>\n",
       "      <td>4065</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.75211</td>\n",
       "      <td>39</td>\n",
       "      <td>393</td>\n",
       "      <td>393</td>\n",
       "      <td>39</td>\n",
       "      <td>4084</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.74328</td>\n",
       "      <td>10</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>10</td>\n",
       "      <td>3677</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.20611</td>\n",
       "      <td>28</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>28</td>\n",
       "      <td>2857</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.24865</td>\n",
       "      <td>42</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>42</td>\n",
       "      <td>2512</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>56</td>\n",
       "      <td>951</td>\n",
       "      <td>951</td>\n",
       "      <td>56</td>\n",
       "      <td>3582</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>71</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>71</td>\n",
       "      <td>4093</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>85</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>85</td>\n",
       "      <td>4090</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.99098</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>4076</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.34140</td>\n",
       "      <td>15</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "      <td>15</td>\n",
       "      <td>3386</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.22977</td>\n",
       "      <td>30</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>30</td>\n",
       "      <td>2624</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.11753</td>\n",
       "      <td>47</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>47</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>62</td>\n",
       "      <td>904</td>\n",
       "      <td>904</td>\n",
       "      <td>62</td>\n",
       "      <td>3756</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>78</td>\n",
       "      <td>1104</td>\n",
       "      <td>1104</td>\n",
       "      <td>78</td>\n",
       "      <td>4101</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>91</td>\n",
       "      <td>733</td>\n",
       "      <td>733</td>\n",
       "      <td>91</td>\n",
       "      <td>4159</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.67112</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>4046</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.82439</td>\n",
       "      <td>24</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>24</td>\n",
       "      <td>3206</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.61373</td>\n",
       "      <td>37</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>37</td>\n",
       "      <td>2716</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>3.86139</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>3.96672</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>4.03584</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>3.86711</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>153</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>4.02074</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>3.99674</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>3.77029</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>3.97145</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>3.86474</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>3.86110</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>3.78556</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>3.73433</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>3.89121</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>3.90839</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>3.86134</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>3.61444</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>3.86074</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>3.86290</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>3.87572</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>3.85790</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>3.61730</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.86293</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>3.85703</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>3.88116</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>3.85917</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>3.64327</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>111</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>3.87425</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>3.88351</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>3.89208</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>3.86941</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6084 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      netMosAvg  d2cLossAvg  e2eJitterAvg  d2cJitterAvg  e2eLossAvg  \\\n",
       "0       3.97741           4           125           125           4   \n",
       "1       3.31220          17           286           286          17   \n",
       "2       2.18346          31           492           492          31   \n",
       "3       1.06915          48           723           723          48   \n",
       "4       1.00000          61           958           958          61   \n",
       "5       1.00000          78          1025          1025          78   \n",
       "6       1.00000          88           965           965          88   \n",
       "7       3.62769          12           146           146          12   \n",
       "8       2.87999          23           366           366          23   \n",
       "9       1.74661          35           562           562          35   \n",
       "10      1.02937          52           841           841          52   \n",
       "11      1.00000          65           981           981          65   \n",
       "12      1.00000          82           972           972          82   \n",
       "13      2.75211          39           393           393          39   \n",
       "14      3.74328          10           214           214          10   \n",
       "15      2.20611          28           441           441          28   \n",
       "16      1.24865          42           621           621          42   \n",
       "17      1.00000          56           951           951          56   \n",
       "18      1.00000          71          1099          1099          71   \n",
       "19      1.00000          85          1092          1092          85   \n",
       "20      3.99098           4           101           101           4   \n",
       "21      3.34140          15           288           288          15   \n",
       "22      2.22977          30           576           576          30   \n",
       "23      1.11753          47           778           778          47   \n",
       "24      1.00000          62           904           904          62   \n",
       "25      1.00000          78          1104          1104          78   \n",
       "26      1.00000          91           733           733          91   \n",
       "27      3.67112           9           136           136           9   \n",
       "28      2.82439          24           369           369          24   \n",
       "29      1.61373          37           606           606          37   \n",
       "...         ...         ...           ...           ...         ...   \n",
       "6054    3.86139           2            24            24           2   \n",
       "6055    3.96672           2            23            23           2   \n",
       "6056    4.03584           1            24            24           1   \n",
       "6057    3.86711           3            32            32           3   \n",
       "6058    4.02074           1            25            25           1   \n",
       "6059    3.99674           2            23            23           2   \n",
       "6060    3.77029           5            24            24           5   \n",
       "6061    3.97145           2            26            26           2   \n",
       "6062    3.86474           3            25            25           3   \n",
       "6063    3.86110           3            27            27           3   \n",
       "6064    3.78556           5            25            25           5   \n",
       "6065    3.73433           5            29            29           5   \n",
       "6066    3.89121           3            24            24           3   \n",
       "6067    3.90839           3            26            26           3   \n",
       "6068    3.86134           4            28            28           4   \n",
       "6069    3.61444           6            27            27           6   \n",
       "6070    3.86074           3            28            28           3   \n",
       "6071    3.86290           3            27            27           3   \n",
       "6072    3.87572           4            26            26           4   \n",
       "6073    3.85790           3            28            28           3   \n",
       "6074    3.61730           7            30            30           7   \n",
       "6075    3.86293           3            27            27           3   \n",
       "6076    3.85703           4            30            30           4   \n",
       "6077    3.88116           4            28            28           4   \n",
       "6078    3.85917           4            29            29           4   \n",
       "6079    3.64327           7            30            30           7   \n",
       "6080    3.87425           4            26            26           4   \n",
       "6081    3.88351           4            27            27           4   \n",
       "6082    3.89208           4            28            28           4   \n",
       "6083    3.86941           4            29            29           4   \n",
       "\n",
       "      jitDepthAvg  playSpeedAvg  \n",
       "0             534          1.20  \n",
       "1            1186          1.00  \n",
       "2            2038          1.00  \n",
       "3            3032          1.00  \n",
       "4            4046          1.00  \n",
       "5            4112          1.00  \n",
       "6            4184          1.00  \n",
       "7            4084          1.00  \n",
       "8            3224          1.00  \n",
       "9            2706          1.00  \n",
       "10           3373          1.00  \n",
       "11           3849          1.00  \n",
       "12           4065          1.00  \n",
       "13           4084          1.00  \n",
       "14           3677          1.00  \n",
       "15           2857          1.00  \n",
       "16           2512          1.00  \n",
       "17           3582          1.00  \n",
       "18           4093          1.00  \n",
       "19           4090          1.00  \n",
       "20           4076          1.00  \n",
       "21           3386          1.00  \n",
       "22           2624          1.00  \n",
       "23           2968          1.00  \n",
       "24           3756          1.00  \n",
       "25           4101          1.00  \n",
       "26           4159          1.00  \n",
       "27           4046          1.00  \n",
       "28           3206          1.00  \n",
       "29           2716          1.00  \n",
       "...           ...           ...  \n",
       "6054           92          1.14  \n",
       "6055           97          1.18  \n",
       "6056           99          1.08  \n",
       "6057          153          1.10  \n",
       "6058          102          1.14  \n",
       "6059           97          1.18  \n",
       "6060           95          1.20  \n",
       "6061           96          1.08  \n",
       "6062          104          1.10  \n",
       "6063           90          1.12  \n",
       "6064           96          1.18  \n",
       "6065           90          1.20  \n",
       "6066          100          1.06  \n",
       "6067           93          1.12  \n",
       "6068          105          1.14  \n",
       "6069          125          1.18  \n",
       "6070           89          1.06  \n",
       "6071           96          1.10  \n",
       "6072           94          1.14  \n",
       "6073           95          1.16  \n",
       "6074           92          1.20  \n",
       "6075           94          1.06  \n",
       "6076           94          1.08  \n",
       "6077           88          1.12  \n",
       "6078           92          1.14  \n",
       "6079          111          1.18  \n",
       "6080           95          1.06  \n",
       "6081           91          1.08  \n",
       "6082          116          1.12  \n",
       "6083          105          1.16  \n",
       "\n",
       "[6084 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netMosAvg</th>\n",
       "      <th>d2cLossAvg</th>\n",
       "      <th>d2cJitterAvg</th>\n",
       "      <th>jitDepthAvg</th>\n",
       "      <th>playSpeedAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.97741</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>534</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.31220</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>1186</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.18346</td>\n",
       "      <td>31</td>\n",
       "      <td>492</td>\n",
       "      <td>2038</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06915</td>\n",
       "      <td>48</td>\n",
       "      <td>723</td>\n",
       "      <td>3032</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>61</td>\n",
       "      <td>958</td>\n",
       "      <td>4046</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>78</td>\n",
       "      <td>1025</td>\n",
       "      <td>4112</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>88</td>\n",
       "      <td>965</td>\n",
       "      <td>4184</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.62769</td>\n",
       "      <td>12</td>\n",
       "      <td>146</td>\n",
       "      <td>4084</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.87999</td>\n",
       "      <td>23</td>\n",
       "      <td>366</td>\n",
       "      <td>3224</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.74661</td>\n",
       "      <td>35</td>\n",
       "      <td>562</td>\n",
       "      <td>2706</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.02937</td>\n",
       "      <td>52</td>\n",
       "      <td>841</td>\n",
       "      <td>3373</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>65</td>\n",
       "      <td>981</td>\n",
       "      <td>3849</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>82</td>\n",
       "      <td>972</td>\n",
       "      <td>4065</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.75211</td>\n",
       "      <td>39</td>\n",
       "      <td>393</td>\n",
       "      <td>4084</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.74328</td>\n",
       "      <td>10</td>\n",
       "      <td>214</td>\n",
       "      <td>3677</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.20611</td>\n",
       "      <td>28</td>\n",
       "      <td>441</td>\n",
       "      <td>2857</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.24865</td>\n",
       "      <td>42</td>\n",
       "      <td>621</td>\n",
       "      <td>2512</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>56</td>\n",
       "      <td>951</td>\n",
       "      <td>3582</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>71</td>\n",
       "      <td>1099</td>\n",
       "      <td>4093</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>85</td>\n",
       "      <td>1092</td>\n",
       "      <td>4090</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.99098</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4076</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.34140</td>\n",
       "      <td>15</td>\n",
       "      <td>288</td>\n",
       "      <td>3386</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.22977</td>\n",
       "      <td>30</td>\n",
       "      <td>576</td>\n",
       "      <td>2624</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.11753</td>\n",
       "      <td>47</td>\n",
       "      <td>778</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>62</td>\n",
       "      <td>904</td>\n",
       "      <td>3756</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>78</td>\n",
       "      <td>1104</td>\n",
       "      <td>4101</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>91</td>\n",
       "      <td>733</td>\n",
       "      <td>4159</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.67112</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "      <td>4046</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.82439</td>\n",
       "      <td>24</td>\n",
       "      <td>369</td>\n",
       "      <td>3206</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.61373</td>\n",
       "      <td>37</td>\n",
       "      <td>606</td>\n",
       "      <td>2716</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>3.86139</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>3.96672</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>97</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>4.03584</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>99</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>3.86711</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>153</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>4.02074</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>102</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>3.99674</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>97</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>3.77029</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>95</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>3.97145</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>96</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>3.86474</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>3.86110</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>3.78556</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>3.73433</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>3.89121</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>3.90839</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>93</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>3.86134</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>105</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>3.61444</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>125</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>3.86074</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>3.86290</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>3.87572</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>94</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>3.85790</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>95</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>3.61730</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.86293</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>94</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>3.85703</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>3.88116</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>3.85917</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>92</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>3.64327</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>3.87425</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>95</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>3.88351</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>91</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>3.89208</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>3.86941</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>105</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6084 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      netMosAvg  d2cLossAvg  d2cJitterAvg  jitDepthAvg  playSpeedAvg\n",
       "0       3.97741           4           125          534          1.20\n",
       "1       3.31220          17           286         1186          1.00\n",
       "2       2.18346          31           492         2038          1.00\n",
       "3       1.06915          48           723         3032          1.00\n",
       "4       1.00000          61           958         4046          1.00\n",
       "5       1.00000          78          1025         4112          1.00\n",
       "6       1.00000          88           965         4184          1.00\n",
       "7       3.62769          12           146         4084          1.00\n",
       "8       2.87999          23           366         3224          1.00\n",
       "9       1.74661          35           562         2706          1.00\n",
       "10      1.02937          52           841         3373          1.00\n",
       "11      1.00000          65           981         3849          1.00\n",
       "12      1.00000          82           972         4065          1.00\n",
       "13      2.75211          39           393         4084          1.00\n",
       "14      3.74328          10           214         3677          1.00\n",
       "15      2.20611          28           441         2857          1.00\n",
       "16      1.24865          42           621         2512          1.00\n",
       "17      1.00000          56           951         3582          1.00\n",
       "18      1.00000          71          1099         4093          1.00\n",
       "19      1.00000          85          1092         4090          1.00\n",
       "20      3.99098           4           101         4076          1.00\n",
       "21      3.34140          15           288         3386          1.00\n",
       "22      2.22977          30           576         2624          1.00\n",
       "23      1.11753          47           778         2968          1.00\n",
       "24      1.00000          62           904         3756          1.00\n",
       "25      1.00000          78          1104         4101          1.00\n",
       "26      1.00000          91           733         4159          1.00\n",
       "27      3.67112           9           136         4046          1.00\n",
       "28      2.82439          24           369         3206          1.00\n",
       "29      1.61373          37           606         2716          1.00\n",
       "...         ...         ...           ...          ...           ...\n",
       "6054    3.86139           2            24           92          1.14\n",
       "6055    3.96672           2            23           97          1.18\n",
       "6056    4.03584           1            24           99          1.08\n",
       "6057    3.86711           3            32          153          1.10\n",
       "6058    4.02074           1            25          102          1.14\n",
       "6059    3.99674           2            23           97          1.18\n",
       "6060    3.77029           5            24           95          1.20\n",
       "6061    3.97145           2            26           96          1.08\n",
       "6062    3.86474           3            25          104          1.10\n",
       "6063    3.86110           3            27           90          1.12\n",
       "6064    3.78556           5            25           96          1.18\n",
       "6065    3.73433           5            29           90          1.20\n",
       "6066    3.89121           3            24          100          1.06\n",
       "6067    3.90839           3            26           93          1.12\n",
       "6068    3.86134           4            28          105          1.14\n",
       "6069    3.61444           6            27          125          1.18\n",
       "6070    3.86074           3            28           89          1.06\n",
       "6071    3.86290           3            27           96          1.10\n",
       "6072    3.87572           4            26           94          1.14\n",
       "6073    3.85790           3            28           95          1.16\n",
       "6074    3.61730           7            30           92          1.20\n",
       "6075    3.86293           3            27           94          1.06\n",
       "6076    3.85703           4            30           94          1.08\n",
       "6077    3.88116           4            28           88          1.12\n",
       "6078    3.85917           4            29           92          1.14\n",
       "6079    3.64327           7            30          111          1.18\n",
       "6080    3.87425           4            26           95          1.06\n",
       "6081    3.88351           4            27           91          1.08\n",
       "6082    3.89208           4            28          116          1.12\n",
       "6083    3.86941           4            29          105          1.16\n",
       "\n",
       "[6084 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.drop('e2eLossAvg', axis=1, inplace=True)\n",
    "df_data.drop('e2eJitterAvg', axis=1, inplace=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4258, 5) (1826, 5)\n"
     ]
    }
   ],
   "source": [
    "data_train =df_data.iloc[:int(df_data.shape[0] * 0.7), :]\n",
    "data_test = df_data.iloc[int(df_data.shape[0] * 0.7):, :]\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wme/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(-1, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92610654, -0.91304348, -0.81174699, -0.75482094,  1.        ],\n",
       "       [ 0.60397094, -0.63043478, -0.56927711, -0.45546373,  0.66666667],\n",
       "       [ 0.05736562, -0.32608696, -0.25903614, -0.06427916,  0.66666667],\n",
       "       ...,\n",
       "       [ 0.90171913, -0.95652174, -0.96385542, -0.95546373,  0.93333333],\n",
       "       [ 0.88673123, -0.93478261, -0.9623494 , -0.95684114,  0.93333333],\n",
       "       [ 0.77177724, -0.89130435, -0.96385542, -0.9600551 ,  0.76666667]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4253, 5, 4) (4253,) (1821, 5, 4) (1821,)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "output_dim = 1\n",
    "batch_size = 256 #每轮训练模型时，样本的数量\n",
    "epochs = 60 #训练60轮次\n",
    "seq_len = 5\n",
    "hidden_size = 128\n",
    "\n",
    "\n",
    "TIME_STEPS = 5\n",
    "INPUT_DIM = 5\n",
    "\n",
    "lstm_units = 64\n",
    "X_train = np.array([data_train[i : i + seq_len, :] for i in range(data_train.shape[0] - seq_len)])\n",
    "y_train = np.array([data_train[i + seq_len, 0] for i in range(data_train.shape[0]- seq_len)])\n",
    "X_test = np.array([data_test[i : i + seq_len, :] for i in range(data_test.shape[0]- seq_len)])\n",
    "y_test = np.array([data_test[i + seq_len, 0] for i in range(data_test.shape[0] - seq_len)])\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.90256659 -0.95652174 -0.96536145 -0.95867769]\n",
      "  [ 0.89525424 -0.93478261 -0.95933735 -0.95454545]\n",
      "  [ 0.89612107 -0.95652174 -0.96084337 -0.95179063]\n",
      "  [ 0.80679419 -0.89130435 -0.95933735 -0.93663912]\n",
      "  [ 0.89202421 -0.93478261 -0.96084337 -0.95821855]]\n",
      "\n",
      " [[ 0.89525424 -0.93478261 -0.95933735 -0.95454545]\n",
      "  [ 0.89612107 -0.95652174 -0.96084337 -0.95179063]\n",
      "  [ 0.80679419 -0.89130435 -0.95933735 -0.93663912]\n",
      "  [ 0.89202421 -0.93478261 -0.96084337 -0.95821855]\n",
      "  [ 0.89978208 -0.95652174 -0.94126506 -0.95224977]]\n",
      "\n",
      " [[ 0.89612107 -0.95652174 -0.96084337 -0.95179063]\n",
      "  [ 0.80679419 -0.89130435 -0.95933735 -0.93663912]\n",
      "  [ 0.89202421 -0.93478261 -0.96084337 -0.95821855]\n",
      "  [ 0.89978208 -0.95652174 -0.94126506 -0.95224977]\n",
      "  [ 0.87076998 -0.93478261 -0.96084337 -0.92745638]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.86781114 -0.91304348 -0.95481928 -0.95684114]\n",
      "  [ 0.87949637 -0.91304348 -0.95783133 -0.95959596]\n",
      "  [ 0.86884746 -0.91304348 -0.9563253  -0.95775941]\n",
      "  [ 0.7642954  -0.84782609 -0.95481928 -0.94903581]\n",
      "  [ 0.87615012 -0.91304348 -0.96084337 -0.956382  ]]\n",
      "\n",
      " [[ 0.87949637 -0.91304348 -0.95783133 -0.95959596]\n",
      "  [ 0.86884746 -0.91304348 -0.9563253  -0.95775941]\n",
      "  [ 0.7642954  -0.84782609 -0.95481928 -0.94903581]\n",
      "  [ 0.87615012 -0.91304348 -0.96084337 -0.956382  ]\n",
      "  [ 0.88063438 -0.91304348 -0.95933735 -0.95821855]]\n",
      "\n",
      " [[ 0.86884746 -0.91304348 -0.9563253  -0.95775941]\n",
      "  [ 0.7642954  -0.84782609 -0.95481928 -0.94903581]\n",
      "  [ 0.87615012 -0.91304348 -0.96084337 -0.956382  ]\n",
      "  [ 0.88063438 -0.91304348 -0.95933735 -0.95821855]\n",
      "  [ 0.8847845  -0.91304348 -0.95783133 -0.94674013]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89978208 0.87076998 0.88735593 ... 0.88063438 0.8847845  0.8738063 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(TIME_STEPS, INPUT_DIM))\n",
    "#drop1 = Dropout(0.3)(inputs)\n",
    "\n",
    "x = Conv1D(filters = 64, kernel_size = 1, activation = 'relu')(inputs)  #, padding = 'same'\n",
    "#x = Conv1D(filters=128, kernel_size=5, activation='relu')(output1)#embedded_sequences\n",
    "x = MaxPooling1D(pool_size = 5)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128)\n"
     ]
    }
   ],
   "source": [
    "lstm_out = Bidirectional(LSTM(lstm_units, activation='relu'), name='bilstm')(x)\n",
    "#lstm_out = LSTM(lstm_units,activation='relu')(x)\n",
    "print(lstm_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "from keras import initializers\n",
    "# Attention GRU network  未用     \n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.get('normal')\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==128\n",
    "        #self.W = self.init((input_shape[-1],1))\n",
    "        self.W = self.init((input_shape[-1],))\n",
    "        #self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "        \n",
    "        ai = K.exp(eij)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "        \n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nl_att = AttLayer()(lstm_out)\\noutput = Dense(1, activation='sigmoid')(l_att)\\nprint(output.shape)\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "l_att = AttLayer()(lstm_out)\n",
    "output = Dense(1, activation='sigmoid')(l_att)\n",
    "print(output.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, merge\n",
    "from keras import layers\n",
    "# ATTENTION PART STARTS HERE\n",
    "attention_probs = Dense(128, activation='sigmoid', name='attention_vec')(lstm_out)\n",
    "#attention_mul=layers.merge([stm_out,attention_probs], output_shape],mode='concat',concat_axis=1))\n",
    "attention_mul =Multiply()([lstm_out, attention_probs])\n",
    "#attention_mul = merge([lstm_out, attention_probs],output_shape=32, name='attention_mul', mode='mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 5, 4)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 5, 64)        320         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 64)        0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1, 64)        0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bilstm (Bidirectional)          (None, 128)          66048       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Dense)           (None, 128)          16512       bilstm[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 128)          0           bilstm[0][0]                     \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         multiply_3[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 83,009\n",
      "Trainable params: 83,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "#output = Dense(10, activation='sigmoid')(drop2)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-12009722e97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE Train loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=False)\n",
    "y_pred = model.predict(X_test)\n",
    "print('MSE Train loss:', model.evaluate(X_train, y_train, batch_size=batch_size))\n",
    "print('MSE Test loss:', model.evaluate(X_test, y_test, batch_size=batch_size))\n",
    "plt.plot(y_test, label='test')\n",
    "plt.plot(y_pred, label='pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 37312/37312 [==============================] - 3s 92us/step - loss: 0.1865 Epoch 2/60 37312/37312 [==============================] - 2s 46us/step - loss: 0.0514 Epoch 3/60 37312/37312 [==============================] - 2s 42us/step - loss: 0.0442 Epoch 4/60 37312/37312 [==============================] - 2s 44us/step - loss: 0.0439 Epoch 5/60 37312/37312 [==============================] - 1s 39us/step - loss: 0.0436 Epoch 6/60 37312/37312 [==============================] - 1s 35us/step - loss: 0.0432 Epoch 7/60 37312/37312 [==============================] - 1s 35us/step - loss: 0.0429 Epoch 8/60 37312/37312 [==============================] - 1s 39us/step - loss: 0.0426 Epoch 9/60 37312/37312 [==============================] - 1s 37us/step - loss: 0.0424 Epoch 10/60 37312/37312 [==============================] - 1s 34us/step - loss: 0.0422 Epoch 11/60 37312/37312 [==============================] - 1s 36us/step - loss: 0.0420 Epoch 12/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0419 Epoch 13/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0418 Epoch 14/60 37312/37312 [==============================] - 1s 38us/step - loss: 0.0417 Epoch 15/60 37312/37312 [==============================] - 2s 42us/step - loss: 0.0417 Epoch 16/60 37312/37312 [==============================] - 2s 45us/step - loss: 0.0416 Epoch 17/60 37312/37312 [==============================] - 1s 39us/step - loss: 0.0416 Epoch 18/60 37312/37312 [==============================] - 2s 42us/step - loss: 0.0416 Epoch 19/60 37312/37312 [==============================] - 2s 44us/step - loss: 0.0416 Epoch 20/60 37312/37312 [==============================] - 1s 35us/step - loss: 0.0416 Epoch 21/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0416 Epoch 22/60 37312/37312 [==============================] - 2s 41us/step - loss: 0.0416 Epoch 23/60 37312/37312 [==============================] - 1s 37us/step - loss: 0.0415 Epoch 24/60 37312/37312 [==============================] - 1s 35us/step - loss: 0.0416 Epoch 25/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0415 Epoch 26/60 37312/37312 [==============================] - 2s 41us/step - loss: 0.0415 Epoch 27/60 37312/37312 [==============================] - 2s 46us/step - loss: 0.0415 Epoch 28/60 37312/37312 [==============================] - 2s 47us/step - loss: 0.0415 Epoch 29/60 37312/37312 [==============================] - 2s 43us/step - loss: 0.0414 Epoch 30/60 37312/37312 [==============================] - 1s 39us/step - loss: 0.0414 Epoch 31/60 37312/37312 [==============================] - 2s 41us/step - loss: 0.0414 Epoch 32/60 37312/37312 [==============================] - 2s 42us/step - loss: 0.0414 Epoch 33/60 37312/37312 [==============================] - 1s 37us/step - loss: 0.0414 Epoch 34/60 37312/37312 [==============================] - 2s 44us/step - loss: 0.0414 Epoch 35/60 37312/37312 [==============================] - 2s 49us/step - loss: 0.0413 Epoch 36/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0413 Epoch 37/60 37312/37312 [==============================] - 1s 35us/step - loss: 0.0413 Epoch 38/60 37312/37312 [==============================] - 2s 48us/step - loss: 0.0413 Epoch 39/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0412 Epoch 40/60 37312/37312 [==============================] - 1s 38us/step - loss: 0.0413 Epoch 41/60 37312/37312 [==============================] - 2s 42us/step - loss: 0.0412 Epoch 42/60 37312/37312 [==============================] - 2s 41us/step - loss: 0.0412 Epoch 43/60 37312/37312 [==============================] - 1s 36us/step - loss: 0.0412 Epoch 44/60 37312/37312 [==============================] - 1s 40us/step - loss: 0.0412 Epoch 45/60 37312/37312 [==============================] - 2s 43us/step - loss: 0.0412 Epoch 46/60 37312/37312 [==============================] - 1s 37us/step - loss: 0.0412 Epoch 47/60 37312/37312 [==============================] - 1s 38us/step - loss: 0.0412 Epoch 48/60 37312/37312 [==============================] - 2s 43us/step - loss: 0.0412 Epoch 49/60 37312/37312 [==============================] - 1s 39us/step - loss: 0.0411 Epoch 50/60 37312/37312 [==============================] - 1s 37us/step - loss: 0.0411 Epoch 51/60 37312/37312 [==============================] - 2s 42us/step - loss: 0.0411 Epoch 52/60 37312/37312 [==============================] - 2s 43us/step - loss: 0.0411 Epoch 53/60 37312/37312 [==============================] - 1s 38us/step - loss: 0.0411 Epoch 54/60 37312/37312 [==============================] - 2s 47us/step - loss: 0.0410 Epoch 55/60 37312/37312 [==============================] - 2s 50us/step - loss: 0.0410 Epoch 56/60 37312/37312 [==============================] - 2s 43us/step - loss: 0.0410 Epoch 57/60 37312/37312 [==============================] - 2s 48us/step - loss: 0.0410 Epoch 58/60 37312/37312 [==============================] - 2s 50us/step - loss: 0.0410 Epoch 59/60 37312/37312 [==============================] - 2s 40us/step - loss: 0.0410 Epoch 60/60 37312/37312 [==============================] - 2s 45us/step - loss: 0.0410 37312/37312 [==============================] - 1s 20us/step MSE Train loss: 0.04148709757006819 15988/15988 [==============================] - 0s 15us/step MSE Test loss: 0.0005358342003804944\n"
     ]
    }
   ],
   "source": [
    "print(\"Epoch 1/60 \\\n",
    "37312/37312 [==============================] - 3s 92us/step - loss: 0.1865 \\\n",
    "Epoch 2/60 \\\n",
    "37312/37312 [==============================] - 2s 46us/step - loss: 0.0514 \\\n",
    "Epoch 3/60 \\\n",
    "37312/37312 [==============================] - 2s 42us/step - loss: 0.0442 \\\n",
    "Epoch 4/60 \\\n",
    "37312/37312 [==============================] - 2s 44us/step - loss: 0.0439 \\\n",
    "Epoch 5/60 \\\n",
    "37312/37312 [==============================] - 1s 39us/step - loss: 0.0436 \\\n",
    "Epoch 6/60 \\\n",
    "37312/37312 [==============================] - 1s 35us/step - loss: 0.0432 \\\n",
    "Epoch 7/60 \\\n",
    "37312/37312 [==============================] - 1s 35us/step - loss: 0.0429 \\\n",
    "Epoch 8/60 \\\n",
    "37312/37312 [==============================] - 1s 39us/step - loss: 0.0426 \\\n",
    "Epoch 9/60 \\\n",
    "37312/37312 [==============================] - 1s 37us/step - loss: 0.0424 \\\n",
    "Epoch 10/60 \\\n",
    "37312/37312 [==============================] - 1s 34us/step - loss: 0.0422 \\\n",
    "Epoch 11/60 \\\n",
    "37312/37312 [==============================] - 1s 36us/step - loss: 0.0420 \\\n",
    "Epoch 12/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0419 \\\n",
    "Epoch 13/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0418 \\\n",
    "Epoch 14/60 \\\n",
    "37312/37312 [==============================] - 1s 38us/step - loss: 0.0417 \\\n",
    "Epoch 15/60 \\\n",
    "37312/37312 [==============================] - 2s 42us/step - loss: 0.0417 \\\n",
    "Epoch 16/60 \\\n",
    "37312/37312 [==============================] - 2s 45us/step - loss: 0.0416 \\\n",
    "Epoch 17/60 \\\n",
    "37312/37312 [==============================] - 1s 39us/step - loss: 0.0416 \\\n",
    "Epoch 18/60 \\\n",
    "37312/37312 [==============================] - 2s 42us/step - loss: 0.0416 \\\n",
    "Epoch 19/60 \\\n",
    "37312/37312 [==============================] - 2s 44us/step - loss: 0.0416 \\\n",
    "Epoch 20/60 \\\n",
    "37312/37312 [==============================] - 1s 35us/step - loss: 0.0416 \\\n",
    "Epoch 21/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0416 \\\n",
    "Epoch 22/60 \\\n",
    "37312/37312 [==============================] - 2s 41us/step - loss: 0.0416 \\\n",
    "Epoch 23/60 \\\n",
    "37312/37312 [==============================] - 1s 37us/step - loss: 0.0415 \\\n",
    "Epoch 24/60 \\\n",
    "37312/37312 [==============================] - 1s 35us/step - loss: 0.0416 \\\n",
    "Epoch 25/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0415 \\\n",
    "Epoch 26/60 \\\n",
    "37312/37312 [==============================] - 2s 41us/step - loss: 0.0415 \\\n",
    "Epoch 27/60 \\\n",
    "37312/37312 [==============================] - 2s 46us/step - loss: 0.0415 \\\n",
    "Epoch 28/60 \\\n",
    "37312/37312 [==============================] - 2s 47us/step - loss: 0.0415 \\\n",
    "Epoch 29/60 \\\n",
    "37312/37312 [==============================] - 2s 43us/step - loss: 0.0414 \\\n",
    "Epoch 30/60 \\\n",
    "37312/37312 [==============================] - 1s 39us/step - loss: 0.0414 \\\n",
    "Epoch 31/60 \\\n",
    "37312/37312 [==============================] - 2s 41us/step - loss: 0.0414 \\\n",
    "Epoch 32/60 \\\n",
    "37312/37312 [==============================] - 2s 42us/step - loss: 0.0414 \\\n",
    "Epoch 33/60 \\\n",
    "37312/37312 [==============================] - 1s 37us/step - loss: 0.0414 \\\n",
    "Epoch 34/60 \\\n",
    "37312/37312 [==============================] - 2s 44us/step - loss: 0.0414 \\\n",
    "Epoch 35/60 \\\n",
    "37312/37312 [==============================] - 2s 49us/step - loss: 0.0413 \\\n",
    "Epoch 36/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0413 \\\n",
    "Epoch 37/60 \\\n",
    "37312/37312 [==============================] - 1s 35us/step - loss: 0.0413 \\\n",
    "Epoch 38/60 \\\n",
    "37312/37312 [==============================] - 2s 48us/step - loss: 0.0413 \\\n",
    "Epoch 39/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0412 \\\n",
    "Epoch 40/60 \\\n",
    "37312/37312 [==============================] - 1s 38us/step - loss: 0.0413 \\\n",
    "Epoch 41/60 \\\n",
    "37312/37312 [==============================] - 2s 42us/step - loss: 0.0412 \\\n",
    "Epoch 42/60 \\\n",
    "37312/37312 [==============================] - 2s 41us/step - loss: 0.0412 \\\n",
    "Epoch 43/60 \\\n",
    "37312/37312 [==============================] - 1s 36us/step - loss: 0.0412 \\\n",
    "Epoch 44/60 \\\n",
    "37312/37312 [==============================] - 1s 40us/step - loss: 0.0412 \\\n",
    "Epoch 45/60 \\\n",
    "37312/37312 [==============================] - 2s 43us/step - loss: 0.0412 \\\n",
    "Epoch 46/60 \\\n",
    "37312/37312 [==============================] - 1s 37us/step - loss: 0.0412 \\\n",
    "Epoch 47/60 \\\n",
    "37312/37312 [==============================] - 1s 38us/step - loss: 0.0412 \\\n",
    "Epoch 48/60 \\\n",
    "37312/37312 [==============================] - 2s 43us/step - loss: 0.0412 \\\n",
    "Epoch 49/60 \\\n",
    "37312/37312 [==============================] - 1s 39us/step - loss: 0.0411 \\\n",
    "Epoch 50/60 \\\n",
    "37312/37312 [==============================] - 1s 37us/step - loss: 0.0411 \\\n",
    "Epoch 51/60 \\\n",
    "37312/37312 [==============================] - 2s 42us/step - loss: 0.0411 \\\n",
    "Epoch 52/60 \\\n",
    "37312/37312 [==============================] - 2s 43us/step - loss: 0.0411 \\\n",
    "Epoch 53/60 \\\n",
    "37312/37312 [==============================] - 1s 38us/step - loss: 0.0411 \\\n",
    "Epoch 54/60 \\\n",
    "37312/37312 [==============================] - 2s 47us/step - loss: 0.0410 \\\n",
    "Epoch 55/60 \\\n",
    "37312/37312 [==============================] - 2s 50us/step - loss: 0.0410 \\\n",
    "Epoch 56/60 \\\n",
    "37312/37312 [==============================] - 2s 43us/step - loss: 0.0410 \\\n",
    "Epoch 57/60 \\\n",
    "37312/37312 [==============================] - 2s 48us/step - loss: 0.0410 \\\n",
    "Epoch 58/60 \\\n",
    "37312/37312 [==============================] - 2s 50us/step - loss: 0.0410 \\\n",
    "Epoch 59/60 \\\n",
    "37312/37312 [==============================] - 2s 40us/step - loss: 0.0410 \\\n",
    "Epoch 60/60 \\\n",
    "37312/37312 [==============================] - 2s 45us/step - loss: 0.0410 \\\n",
    "37312/37312 [==============================] - 1s 20us/step \\\n",
    "MSE Train loss: 0.04148709757006819 \\\n",
    "15988/15988 [==============================] - 0s 15us/step \\\n",
    "MSE Test loss: 0.0005358342003804944\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
